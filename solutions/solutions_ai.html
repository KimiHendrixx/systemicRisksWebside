<!DOCTYPE html>
<html lang="de">

<head>
      
    <meta charset="UTF-8" />
      
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
      
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      
    <link rel="stylesheet" href="../styles.css" />
    <link rel="stylesheet" href="styles_solutions.css" />
    <link rel="stylesheet" href="../styles_intro_content.css" />


    <link href="https://fonts.googleapis.com/css2?family=Bebas+Neue&display=swap" rel="stylesheet">

      <title>Document</title>
</head>

<body>

    <!-- NAVBAR -->
    <!-- HEAD WITH LOGO AND NAVBAR -->
    <header>

        <a href="index.html">
            <img class="logo" src="../images/logo white.png">
        </a>

        <input type="checkbox" id="menu-bar">
        <label for="menu-bar">Menu</label>

        <nav class="navbar">
            <ul class="parent_ul">

                <li><a href="#">Klimawandel▾</a>
                    <ul class="dropdown_ul">
                        <li><a href="../intros/intro_climate.html">Einführung</a></li>
                        <li><a href="solutions_climate_main.html">Klimamilderung</a></li>
                        <li><a href="../success.html">Erfolge für den Klimaschutz</a></li>
                        <li><a href="../literature/lit_climate.html">Literatur</a></li>
                    </ul>
                </li>

                <li><a href="#">Pandemien▾</a>
                    <ul class="dropdown_ul">
                        <li><a href="../intros/intro_pandemic.html">Einführung</a></li>
                        <li><a href="solutions_pandemic.html">Lösungsansätze</a></li>
                        <li><a href="../literature/lit_pandemic.html">Literatur</a></li>
                    </ul>
                </li>

                <li><a href="#">Künstliche Intelligenz▾</a>
                    <ul class="dropdown_ul">
                        <li><a href="../intros/intro_ai.html">Einführung</a></li>
                        <li><a href="solutions_ai.html">KI-Sicherheit</a></li>
                        <li><a href="../literature/lit_ai.html">Literatur</a></li>
                    </ul>
                </li>

                <li><a href="#">Krieg▾</a>
                    <ul class="dropdown_ul">
                        <li><a href="../intros/intro_war.html">Einführung</a></li>
                        <li><a href="solutions_war_main.html">Lösungsansätze</a></li>
                        <li><a href="../literature/lit_war.html">Literatur</a></li>
                    </ul>
                </li>

                <li><a href="#">Wirtschaftskrise▾</a>
                    <ul class="dropdown_ul">
                        <li><a href="../intros/intro_eco.html">Einführung</a></li>
                        <li><a href="solutions_eco.html">Lösungsansätze</a></li>
                        <li><a href="../literature/lit_eco.html">Literatur</a></li>
                    </ul>
                </li>


            </ul>
        </nav>

    </header>

    <!-- HEADLINE AND IMAGE -->

    <div class="headline_div" id="headline_div_solutions">
        <img class="headline_image_solutions" src="../images/blue_texture.jpg">
        <h1 class="headline_intro"> KI-Sicherheit
            <hr class="hr_intro"> Ansätze
        </h1>
    </div>



    <!-- SOLUTIONS -->

    <!-- FOUNDATION -->
    <div class="div_solutions">
        <h1 id="headline_basics">Grundlegendes</h1>
        <p class="text_solutions">Das grundlegende Ziel für einen sicheren Umgang mit künstlicher Intelligenz ist,
            dass letztendlich Menschen die Kontrolle über die Technologie behalten, und zwar nicht einige wenige,
            sondern im Idealfall jeder Einzelne. Ohne Einrichtung vielschichtiger Kontrollinstanzen ist es sehr
            wahrscheinlich, dass einige wenige Menschen die Kontrolle über die KI-Technologie übernehmen und damit viele
            Menschen kontrollieren oder die KI-Technologie uns am Ende selbst kontrolliert. Dieser Ausgang ist logisch
            absehbar, wenn man verstanden hat, wie mächtig künstliche Intelligenz schon heute ist und durch den stetigen
            Zuwachs an systemischer Komplexität in Zukunft noch werden kann.
            <br><br>

            Schon heute untergraben viele KI-Technologien unser Recht auf individuelle Selbstentfaltung, indem sie im
            Internet kontrollieren, auf welche Informationen wir wie und wann Zugriff haben und damit in hohem Maße
            manipulativ sind. „Es geht hier um nicht weniger als unsere wichtigsten verfassungsmäßig garantierten
            Rechte.“, wie es treffend in dem Artikel „Das digitale Manifest“ erschienen im Spektrum beschrieben
            wird.<sup>1</sup>
            <br><br>

            Ein denkbarer Ansatz für mehr KI-Sicherheit könnte aus einer vielschichtigen Kontrolle über die Technologie
            durch den Menschen bestehen. <b>Dabei könnten die Gesellschaft, die Politik und die Forschung die drei
                Hauptinstanzen darstellen.</b>
        </p>
    </div>

    <br><br><br>


    <!-- GESELLSCHAFT -->

    <h1 class="headline_solutions">Kontrolle auf gesellschaftlicher Ebene</h1>

    <img class="img_solutions" src="../content_pages_ai/images_ai/gesellschaft.jpg">

    <div class="div_solutions">
        <p class="text_solutions">Zunächst bedarf es einer allgemeinen Aufklärung über den Einfluss, die Tragweite
            und die Folgen aktuell eingesetzter und zukünftig möglicher eingesetzter KIs. Diese würde erheblich
            vorangetrieben werden, durch die Förderung von sachlich-rationalen Diskursen über das Thema. Erreicht werden
            kann dies auf gesellschaftlicher Ebene durch die Eigeninitiative von Menschen, welche sich über das Thema KI
            informieren und dann einen Diskurs anstoßen. Dies kann auf jeder Ebene geschehen, egal ob in der Familie,
            mit Freunden, in Bildungsstätten, im Unternehmen oder als Gesellschaftsumfrage. Durch die Aufklärung und
            durch anschließende Diskurse, kann die Gesellschaft Forderungen an die Regierung und an die Forschung
            stellen, welche ihrer Meinung nach wichtig für einen sicheren Umgang mit künstlicher Intelligenz sind. Wer
            noch mehr zu diesem Ziel beitragen möchte, kann auch darüber nachdenken, seine Karriere entsprechend
            auszurichten. Ein gutes Leitkonzept bietet das Buch „80,000 hours“ von Benjamin Todd und die dazu passende
            Internetseite.<sup>2</sup></p>
    </div>


    <!-- POLITIK -->

    <h1 class="headline_solutions">Kontrolle auf politischer Ebene</h1>

    <img class="img_solutions" src="../content_pages_ai/images_ai/politics.jpg">

    <div class="div_solutions">
        <p class="text_solutions">Der Staat sollte gesetzliche Rahmenbedingungen für die Herstellung und den Einsatz
            von künstlicher Intelligenz schaffen, welche nicht maximalen Profit zum höchsten Ziel machen, sondern die
            menschliche Sicherheit. Diese sollten in Absprache mit der Gesellschaft, der Forschung und der
            Ethikkommission beschlossen, stetig überprüft und falls nötig angepasst werden. Ein logischer Ansatz für
            solche Rahmenbedingungen wäre zum Beispiel der Beschluss, dass zur Herstellung und zum Einsatz von
            KI-Systemen eine Genehmigung vom Staat benötigt wird, ebenso wie zur Durchführung von Forschungsprojekte zu
            diesem Thema. Zudem könnte festgelegt werden, dass zur Förderung eines transparenten Einsatzes von KI, diese
            fortan gekennzeichnet werden muss. Anderweitig könnte der Staat für mehr Sicherheit sorgen, durch die
            priorisierte Vergabe von Forschungsgeldern für Projekte, welche sich mit der Analyse und Prävention von
            Risiken der KI-Entwicklung beschäftigen. Eine allgemeine strenge Kontrolle der politischen Aktivitäten sowie
            von Forschungsprojekten zum Thema KI durch die Ethikkommission, ist ratsam.</p>
    </div>



    <!-- FORSCHUNG -->

    <h1 class="headline_solutions">Kontrolle durch die Forschung</h1>

    <img class="img_solutions" src="../content_pages_ai/images_ai/research.jpg">

    <div class="div_solutions">
        <p class="text_solutions">Um die Gesellschaft zu unterstützen, sollte die Forschung allgemeine Informationen
            zum Thema KI, zu den aktuellen Forschungsergebnissen und dem aktuellen Einsatz von KI für alle Menschen
            zugänglich machen. Wichtig dafür sind das Sammeln, Vereinfachen und auch Übersetzen der Informationen. Es
            sollte verstärkt Forschung zum Thema KI-Sicherheit betrieben werden, in welcher wichtige gesetzliche
            Rahmenbedingungen erarbeitet werden können, welche dann an die Politik weitergegeben werden können. Eine
            weitere wichtige Aufgabe ist die Erforschung der Leidensfähigkeit von künstlich intelligenten Systemen,
            welche unter der Aufsicht der Ethikkommission und unter Einhaltung festgelegter ethischer Rahmenbedingungen
            ablaufen sollte. Internationale Forschungskollaborationen können das Risiko eines technologischen
            Wettrüstens verringern.</p>
    </div>

    <div class="lit_intro_div" id="lit_ai">
        <h1 class="headline_lit">Literatur</h1>
        <hr class="hr_lit">
        <br>
        <p class="text_lit">
            <a href="https://www.spektrum.de/news/wie-algorithmen-und-big-data-unsere-zukunft-bestimmen/1375933"
                target="_blank">1. Helbing et al. (2022). Digitale Demokratie statt Datendiktatur. 17.12.2015,
                Spektrum. <sub>zuletzt aufgerufen am: 19.10.22</sub></a><br><br>

            <a href="https://80000hours.org/articles/how-to-reduce-existential-risk/" target="_blank">2. Arden Koehler.
                How to use your career to help reduce existential risk. 80,000
                Hours Website, August 2020. <sub>zuletzt aufgerufen am: 19.10.22</sub></a><br><br>

            <a href="https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines"
                target="_blank">3. Ajeya Cotra. Two-year update on my personal AI timelines. Lesswrong,
                03.08.2022. <sub>zuletzt aufgerufen am: 06.03.23</sub></a><br><br>

            <a href="https://80000hours.org/problem-profiles/artificial-intelligence/#what-can-you-do-concretely-to-help"
                target="_blank">4. Benjamin Hilton. Preventing an AI-related catastrophe. 80,000 Hours Webseite,
                August 2022. <sub>zuletzt aufgerufen am: 06.03.23</sub></a><br><br>

        </p>


    </div>

    <!-- ABOUT  FOOTER LIGHT-->

    <div class="zoom_div" id="about"></div>
    <div class="flex_div" id="flex_about_light">
        <div class="div_about_left">
            <h3 class="headline_about_light">About</h3>
            <h3 class="subheadline_about_light">Bei wissenschaftlichen Fragen/ Anfragen für Praktika</h3>
            <p class="text_dark">
                <b>Thomas Dandekar</b>
                <br>
                Member of the first board of directors
                <br>Chair of Bioinformatics
                <br>Biozentrum
                <br>Am Hubland
                <br>D-97074 Wuerzburg
                <br>dandekar@biozentrum.uni-wuerzburg.de
            </p>
        </div>

        <div class="div_about_right" id="div_about_small">
            <h3 class="headline_about_light" id="hl_invis">I'm insvisible</h3>
            <h3 class="subheadline_about_light">Bei sonstigen Anliegen</h3>
            <p class="text_dark">
                <b>Eva-Maria Fischer</b>
                <br>Department of Bioinformatics
                <br>Biozentrum
                <br>Am Hubland
                <br>D-97074 Wuerzburg
                <br>eva.fischer@uni-wuerzburg.de
            </p>
        </div>
    </div>






</body>

</html>